---
########################################################
#             Ankus Local Configuration
########################################################
install_mode: 'local'

########################################################
# SSH Configuration
########################################################
# * ssh_key : root users ssh private key to log into machines
# * ssh_user: username used to log into machines, change this if the user is 
#             not 'root', ssh_user should have password less sudo privileges 
#             (you can make a user password-less sudo by adding the user to
#              /etc/sudoers file like this  `ssh_user  ALL=(ALL) NOPASSWD:ALL`)
########################################################
ssh_key: '~/.ssh/id_rsa'         #<<<<<<<<<<<<<< UPDATE THIS
ssh_user: 'root'                 #<<<<<<<<<<<<<< UPDATE THIS

########################################################
# Controller
########################################################
# * controller: fqdn of the server which will host 
#               - puppet master 
#               - kerberos server (if security is enabled)
#               - nagios server (if alerting is enabled)
#               - ganglia server (if monitoring is enabled)
#               - logstash indexer (if log aggregation is enabled)
#   The value of the controller could be 'localhost' if running ankus from
#   controller.
########################################################
controller: 'controller.ops.cw.com'

########################################################
# Hadoop Cluster Configuration
########################################################
# * hadoop_deploy: specifies whether to deploy hadoop or not
#   * ha (hadoop high availability configuration):
#       enabled => hadoop ha is enabled with two namenode(s) with auto failover
#                  using zookeeper failover controller
#       disabled => hadoop ha is not setup and only one namenode will be
#                   installed and configured
#   * namenode:
#       fqdn of hosts on which namenode should be deployed
#       if hadoop_ha is enabled, pass in two fqdn(s)
#       if hadoop_ha is disabled, pass in one fqdn
#   * secondarynamenode:
#       if hadoop_ha is disabled pass in a fqdn in which secondarynamenode is 
#       configured
#   * journal_quorum:
#       if hadoop_ha is enabled|auto, pass in odd number of fqdn(s). Journal 
#       nodes are used to store metadata in high availability configuration
#   * mapreduce: mapreduce specific configuration, specifies whether to deploy 
#                mapreduce framework or not
#       * type: specifies mapreduce framework type to deploy (mr1 or mr2)
#       * master: fqdn of machine on which mapreduce master will be deployed
#   * ecosystem: list of ecosystem tools to deploy
#       hive  - installs and configures hive, which is data warehouse system for 
#               Hadoop (http://hive.apache.org/)
#       pig   - installs and configures pig, is a platform for analyzing large 
#               data sets (http://pig.apache.org/)
#       sqoop - installs and configures sqoop, is a tool designed for 
#               efficiently transferring bulk data between hadoop & rdbms & mpp
#               (http://sqoop.apache.org/)
#       oozie - installs and configures oozie, is a workflow scheduler system to
#               manage Apache Hadoop jobs 
#               (http://oozie.apache.org/)
#       hue   - installs and configures hue, the open source Apache Hadoop UI
#               (http://cloudera.github.io/hue/)
#   * data_dirs:
#       list of directories on which hadoop worker nodes writes data to
#       (recommended to use multiple volumes & to mount each directory path
#        on separate volumes for higher throughput)
#       default: ['/data/hadoop']
#   * master_dirs:
#       list of directories to be used by master nodes to write data to
#       default: ['/data/hadoop']
#   * packages_source:
#       specifies which packages to use, available sources:
#         'cdh' - installs cloudera cdh packages
#         'hdp' - installs hortonworks hdp packages
#       default: cdh
#
# ===============DEPLOYMENT SCENARIO 1==================
#        TO DEPLOY HADOOP (HA) with MapReduce
# ======================================================
# hadoop_deploy:
#   ha: 'enabled'
#   namenode:
#     - 'namenode001.ops.cw.com'
#     - 'namenode002.ops.cw.com'
#   journal_quorum:
#     - 'utils001.ops.cw.com'
#   mapreduce:
#     type: 'mr1'
#     master: 'jt.ops.cw.com'
#   ecosystem:
#     - 'hive'
#     - 'pig'
#     - 'sqoop'
#     - 'oozie'
#   data_dirs:
#     - '/data/hadoop/1'
#     - '/data/hadoop/2'
#     - '/data/hadoop/3'
#     - '/data/hadoop/4'
#   master_dirs:
#     - '/data/hadoop/1'
#     - '/data/hadoop/2'
#
# ===============DEPLOYMENT SCENARIO 2==================
#       TO DEPLOY HADOOP (NON-HA) with MapReduce
# ======================================================
# hadoop_deploy:
#   ha: 'disabled'
#   namenode:
#     - 'namenode001.ops.cw.com'
#   secondarynamenode: 'snn.ops.cw.com'
#   mapreduce:
#     type: 'mr1'
#     master: 'jt.ops.cw.com'
#   ecosystem:
#     - 'hive'
#     - 'pig'
#     - 'sqoop'
#     - 'oozie'
#
# ===============DEPLOYMENT SCENARIO 3==================
# TO DEPLOY HADOOP (just HDFS) suitable for HBase deployments
# ======================================================
# hadoop_deploy:
#   ha: 'disabled'
#   namenode:
#     - 'namenode001.ops.cw.com'
#   secondarynamenode: 'snn.ops.cw.com'
#   mapreduce: 'disabled'
#
# ===============DEPLOYMENT SCENARIO 4==================
#              DISABLE HADOOP DEPLOYMENT
# ======================================================
# hadoop_deploy: 'disabled'
#
########################################################
hadoop_deploy: 'disabled'

########################################################
# HBase Cluster configuration
########################################################
# * hbase_deploy: Specify whether to deploy hbase or not
#                   if enabled will install hbase
#                   if disabled hbase will not be deployed
# * master: if hbase_deploy is enabled, specify fqdn(s) of hbase masters
#           to deploy
#
# ===============DEPLOYMENT SCENARIO 1==================
#           TO DEPLOY HBASE (with 2 masters)
# ======================================================
# hbase_deploy:
#   master:
#     - 'hbasemaster001.ops.cw.com'
#     - 'hbasemaster002.ops.cw.com'
#
# ===============DEPLOYMENT SCENARIO 2==================
#               DISABLE HBASE DEPLOYMENT
# ======================================================
# hbase_deploy: 'disabled'
#
########################################################
hbase_deploy: 'disabled'

########################################################
# Zookeeper Quorum Configuration
########################################################
# Required for hadoop_ha, hbase, kafka, storm deployments
# * zookeeper_deploy: Specifies whether to deploy zookeeper or not
# * quorum  : fqdn(s) of hosts to manage zookeeper on, which are used for
#             coordination between several services
#             Recommended: Odd number of hosts
# * dirs    : list of directories to be used by zookeeper daemons to store
#             data. Default: ['/data/zookeeper']
# Note: (zookeepers and journal nodes can co-exist on same machines)
# ===============DEPLOYMENT SCENARIO 1==================
#           TO DEPLOY Zookeeper (with 3 masters)
# ======================================================
# zookeeper_deploy:
#   quorum:
#     - 'zookeeper001.ops.cw.com'
#     - 'zookeeper002.ops.cw.com'
#     - 'zookeeper003.ops.cw.com'
#   dirs:
#     - '/data/zookeeper/1'
#     - '/data/zookeeper/2'
#
# ===============DEPLOYMENT SCENARIO 2==================
#               DISABLE ZooKeeper DEPLOYMENT
# ======================================================
# zookeeper_deploy: 'disabled'
#
########################################################
zookeeper_deploy: 'disabled'

########################################################
# Worker Nodes Configuration
########################################################
#  worker_nodes:
#   list of slave nodes on which hadoop worker daemons will be managed. If
#   hbase is enabled hbase worker daemons are also managed on same machines.
########################################################
worker_nodes:
  - 'worker001.ops.cw.com'
  - 'worker002.ops.cw.com'
  - 'worker003.ops.cw.com'
  - 'worker004.ops.cw.com'
  - 'worker005.ops.cw.com'

########################################################
# Solr Cluster configuration
########################################################
# * solr_deploy: Specify whether to deploy solr or not
#                   if enabled will install solr
#                   if disabled solr will not be deployed
# * hdfs_integration: specifies whether to deploy solr with hdfs integration
#                      or not
# * nodes: specify fqdn(s) of solr nodes to deploy, if hdfs_integration is
#          enabled its optimal to collocate hadoop worker nodes and solr nodes
#
# ===============DEPLOYMENT SCENARIO 1==================
#           TO DEPLOY Solr with HDFS Integration
# ======================================================
# solr_deploy:
#   hdfs_integration: enabled
#   nodes:
#     - 'worker001.ops.cw.com'
#     - 'worker002.ops.cw.com'
#     - 'worker003.ops.cw.com'
#
# ===============DEPLOYMENT SCENARIO 1==================
#        TO DEPLOY Solr without HDFS Integration
# ======================================================
# solr_deploy:
#   hdfs_integration: disabled
#   nodes:
#     - 'solr001.ops.cw.com'
#     - 'solr002.ops.cw.com'
#     - 'solr003.ops.cw.com'
#
# ===============DEPLOYMENT SCENARIO 2==================
#               DISABLE SOLR DEPLOYMENT
# ======================================================
# solr_deploy: 'disabled'
#
########################################################
solr_deploy: 'disabled'

########################################################
# Security
########################################################
# security : if configured sets up kerberos and integrates it with
#            hadoop/hbase and its eco-system
#            possible_values - simple (will not install kerberos)
#                            - kerberos (will install kerberos)
# kerberos_realm : if kerberos is enabled, enter a kerberos realm name
# kerberos_domain: if kerberos is enabled, enter a kerberos domain name
#                  (http://goo.gl/o44h1O)
#
# ===============DEPLOYMENT SCENARIO 1==================
#                DO NOT USE SECURITY
# ======================================================
# security: 'simple'
#
# ===============DEPLOYMENT SCENARIO 2==================
#          ENABLE SECURITY USING KERBEROS
# ======================================================
# security: 'kerberos'
#   kerberos_realm: ANKUS.COM
#   kerberos_domain: ankus.com
#
########################################################
security: 'simple'

########################################################
# Cassandra Cluster Configuration
#  cassandra_deploy   : specifies the deployment of cassandra cluster
#                       possible values: Hash (or) disabled
#   nodes             : nodes on which cassandra is deployed and managed
#   seeds             : list of cassandra seed nodes
#   data_dirs         : mount points to use for data directories
#                       (default: [/var/lib/cassandra/data])
#   commitlog_dirs    : mount points for commit log directories
#                       (default: /var/lib/cassandra/commitlog)
#   saved_caches_dirs : mount points for saved caches directories
#                       (default: /var/lib/cassandra/saved_caches)
# (NOTE: cassandra_nodes and hadoop_slave_nodes can co-exist if willing to 
#        sacrifice performance)
#
# ===============DEPLOYMENT SCENARIO 1==================
#                 TO DEPLOY CASSANDRA 
# ======================================================
# cassandra_deploy:
#   nodes:
#     - 'cassandra001.ops.cw.com'
#     - 'cassandra002.ops.cw.com'
#     - 'cassandra003.ops.cw.com'
#     - 'cassandra004.ops.cw.com'
#     - 'cassandra005.ops.cw.com'
#   seeds:
#     - 'cassandra002.ops.cw.com'
#
# ===============DEPLOYMENT SCENARIO 2==================
#           DISABLE CASSANDRA DEPLOYMENT
# ======================================================
#cassandra_deploy: 'disabled'
#
########################################################
cassandra_deploy: 'disabled'

########################################################
# Kafka Cluster Configuration
#  kafka_deploy: specifies the deployment of kafka cluster
#                possible values: Hash (or) disabled
#   nodes      : nodes on which kafka package is installed (can be used as
#                producers and consumers)
#   brokers    : list of kafka broker nodes
#
# ===============DEPLOYMENT SCENARIO 1==================
#                   TO DEPLOY KAFKA
# ======================================================
# kafka_deploy:
#   brokers:
#     - 'kafka001.ops.cw.com'
#     - 'kafka002.ops.cw.com'
#
# ===============DEPLOYMENT SCENARIO 2==================
#               DISABLE KAFKA DEPLOYMENT
# ======================================================
# kafka_deploy: 'disabled'
#
########################################################
kafka_deploy: 'disabled'

########################################################
# Storm Cluster Configuration
#  storm_deploy: specifies the deployment of storm cluster
#                possible values: Hash (or) disabled
#   supervisors: nodes on which storm supervisor daemons are installed
#   master: node on which storm nimbus and ui daemons are installed
#   workers_count: number of worker processes to run per supervisor node
#
# ===============DEPLOYMENT SCENARIO 1==================
#                   TO DEPLOY STORM
# ======================================================
# storm_deploy:
#   supervisors:
#     - 'stormsupervisor001.ops.cw.com'
#     - 'stormsupervisor002.ops.cw.com'
#     - 'stormsupervisor003.ops.cw.com'
#     - 'stormsupervisor004.ops.cw.com'
#     - 'stormsupervisor005.ops.cw.com'
#   master: 'stormmaster001.ops.cw.com'
#   workers_count: 8
#
# ===============DEPLOYMENT SCENARIO 2==================
#               DISABLE STORM DEPLOYMENT
# ======================================================
# storm_deploy: 'disabled'
#
########################################################
storm_deploy: 'disabled'

########################################################
# Management Configuration
########################################################
# monitoring      : whether to enable monitoring if the instances using ganglia
#                   possible values: enabled,disabled
# alerting        : whether to monitor services and send alerts if something
#                   goes wrong based on nagios
#                   possible values: enabled,disabled
#   admin_email   : email address to send alerts (notifications)
# log_aggregation : whether to collect logs from all the services for core
#                   services and make them available through web console
#                   possible values: enabled,disabled
########################################################
monitoring: 'disabled'
alerting: 'disabled'
admin_email: ''                   #<<<<<<<<<<<<<< FILL THIS
log_aggregation: 'disabled'