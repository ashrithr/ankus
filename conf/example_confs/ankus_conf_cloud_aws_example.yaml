---
########################################################
#           Ankus AWS Cloud Configuration
########################################################
install_mode: 'cloud'

########################################################
# Cloud Service Credentials
########################################################
#  aws_access_id => access id of aws user account
#  aws_secret_key => secret key of aws user account
#  aws_machine_type => type of instance to boot (http://aws.amazon.com/ec2/instance-types/)
#  aws_region => aws region in which to deploy the cluster
#  aws_key => ssh_key to inject to aws instances
########################################################
cloud_platform: aws
cloud_credentials:
  aws_access_id: ''                                     #<<<<<<<<<<<<<< FILL THIS
  aws_secret_key: ''                                    #<<<<<<<<<<<<<< FILL THIS
  aws_machine_type: 'm1.large'
  aws_region: 'us-west-1'
  aws_key: 'ankus'
##type of os to boot into cloud instances (supported: CentOS|Ubuntu)
cloud_os_type: CentOS

########################################################
# Hadoop Cluster Configuration
########################################################
# hadoop_deploy: specifies whether to deploy hadoop or not
#   hadoop_ha: specifies whether to deploy highly available hadoop cluster or not
#   mapreduce: specifies whether to deploy mapreduce framework or not
#     type: specifies mapreduce framework type to deploy (mr1 or mr2)
#   hadoop_ecosystem: specifies list of tools to deploy (hive, pig, oozie, sqoop)
#
# ===============DEPLOYMENT SCENARIO 1==================
#               TO DEPLOY HADOOP (NON-HA)
# ======================================================
#hadoop_deploy:
#  hadoop_ha: 'disabled'
#  mapreduce:
#    type: mr1
#  hadoop_ecosystem:
#    - hive
#    - sqoop
#    - pig
#
# ===============DEPLOYMENT SCENARIO 2==================
#               TO DEPLOY HADOOP WITH HA
# ======================================================
#hadoop_deploy:
#  hadoop_ha: 'enabled'
#  mapreduce:
#    type: mr1
#  hadoop_ecosystem:
#    - hive
#    - sqoop
#    - pig
#
# ===============DEPLOYMENT SCENARIO 3==================
#         TO DEPLOY HADOOP WITH NO MAPREDUCE
# ======================================================
#hadoop_deploy:
#  hadoop_ha: 'disabled'
#  mapreduce: 'disabled'
########################################################
hadoop_deploy:
  hadoop_ha: 'disabled'
  mapreduce:
    type: mr1
  hadoop_ecosystem:
    - hive
    - sqoop
    - pig

########################################################
# HBase configuration
########################################################
# hbase_deploy: specifies whether to deploy a hbase cluster or not
#   hbase_master_count: number of hbase master(s) nodes to deploy
#
# ===============DEPLOYMENT SCENARIO 1==================
#                 TO DEPLOY HBASE
# ======================================================
#hbase_deploy:
# hbase_master_count: 1
#
# ===============DEPLOYMENT SCENARIO 2==================
#               DISABLE HBASE DEPLOYMENT
# ======================================================
#hbase_deploy: disabled
#
########################################################
hbase_deploy: disabled

########################################################
# Zookeeper Quorum Configuration
########################################################
# Required when hadoop_ha or hbase is enabled
# zookeeper_quoram_count: specifies the number of zookeeper(s) to launch to coordinate
#   services
########################################################
zookeeper_quorum_count: 1

########################################################
# Slaves specifications (required for hadoop or hbase deployments)
########################################################
# list of slave nodes on which datanode and tasktracker daemons will be installed. If hbase is enabled
# region servers are also installed on same instances.
slave_nodes_count: 3

########################################################
# Cassandra Cluster Configuration
#  cassandra_deploy: specifies the deployment of cassandra cluster
#                    possible values: Hash (or) disabled
#  hadoop_colocation: whether to colocate hadoop slave daemons and cassandra daemons
#  number_of_instances: number of cassandra instances to launch(not required when
#                       collocation instances)
#  number_of_seeds: number of nodes to use as seeds, choosen randomly (defaults: 1)
#
# ===============DEPLOYMENT SCENARIO 1==================
#  TO DEPLOY CASSANDRA (on same nodes as hadoop workers)
# ======================================================
#cassandra_deploy:
# hadoop_colocation: yes
#
# ===============DEPLOYMENT SCENARIO 2==================
#           TO DEPLOY CASSANDRA (on new nodes)
# ======================================================
#cassandra_deploy:
# hadoop_colocation: no
# number_of_instances: 5
# number_of_seeds: 2
#
# ===============DEPLOYMENT SCENARIO 3==================
#           DISABLE CASSANDRA DEPLOYMENT
# ======================================================
#cassandra_deploy: disabled
########################################################
cassandra_deploy: disabled

########################################################
# VOLUMES
########################################################
# Cloud Instances volumes configuration
# volumes: configure extra volumes that are attached to worker instances
#   type: type of the volumes to create, for aws: valid values are instancestore|ebs
#                                        for rackspace valid value is blockstore
#   count: number of volumes to attach to a instance
#   size: size of each volume in GB
# NOTE: ankus aws instances comes pre-built with 250GB of root partition
#
# ===============DEPLOYMENT SCENARIO 1==================
#     CREATE AND ATTACH 4 VOLUMES TO WORKER NODE
# ======================================================
#volumes:
# type: ebs
# count: 4
# size: 100
# ===============DEPLOYMENT SCENARIO 2==================
#           DISABLE CREATING EXTRA VOLUMES
# ======================================================
#volumes: disabled
########################################################
volumes: disabled

########################################################
# Security
########################################################
# security => if configured sets up kerberos and integrates it with hadoop/hbase and its eco-system
#   possible_values: simple => will not install kerberos
#                    kerberos => will install kerberos
# hadoop_kerberos_realm => if kerberos is enabled, enter a kerberos realm name
# hadoop_kerberos_domain => if kerberos is enabled, enter a kerberos domain name
#   (http://web.mit.edu/kerberos/krb5-1.5/krb5-1.5/doc/krb5-admin/domain_realm.html)
#
# ===============DEPLOYMENT SCENARIO 1==================
#                DO NOT USE SECURITY
# ======================================================
#security: simple
#
# ===============DEPLOYMENT SCENARIO 2==================
#          ENABLE SECURITY USING KERBEROS
# ======================================================
#security: kerberos
# hadoop_kerberos_realm: ANKUS.COM
# hadoop_kerberos_domain: ankus.com
########################################################
security: simple

########################################################
# Management Configuration
########################################################
# monitoring (enabled|disabled) => if enabled, ganglia will be setup and configured
# alerting (enabled|disabled) => if enabled, nagios will be setup and configured to monitor
# admin_email => required (if alerting is enabled), email address to send alters (notifications)
# log_aggregation (enabled|disabled) => if enabled, logstash will be installed to aggregate logs from all the servers
########################################################
monitoring: enabled
alerting: disabled
admin_email: 'admin@cw.com'                             #<<<<<<<<<<<<<< FILL THIS
log_aggregation: disabled